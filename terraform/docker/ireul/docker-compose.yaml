# Utilities
networks:
  local-gpt:

volumes:
  open-webui:
  open-webui-models:
  pg-data:

configs:
  pgvector_init:
    content: |
      \c ${POSTGRES_DB-openwebui}
      CREATE EXTENSION IF NOT EXISTS vector;

services:
  # home-assistant:
  #   image: ghcr.io/home-assistant/home-assistant:2025.5.2
  #   container_name: home-assistant
  #   restart: always
  #   security_opt:
  #     - no-new-privileges:true
  #   network_mode: host
  #   privileged: true
  #   volumes:
  #     - ./config/home-assistant:/config
  #     - /etc/localtime:/etc/localtime:ro
  #     - /run/dbus:/run/dbus:ro
  #   healthcheck:
  #     test: curl -fs http://localhost:8123 || exit 1
  #     interval: 30s
  #     timeout: 10s
  #     start_period: 30s
  #     retries: 3
  
  immich:
    container_name: immich
    image: ghcr.io/immich-app/immich-server:v1.132.3
    hostname: immich
    restart: always
    environment:
      - PUID=${UID}
      - PGID=${GID}
      - TZ=${TZ}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_HOSTNAME=database
      - DB_USERNAME=${DB_USERNAME}
      - DB_DATABASE_NAME=${DB_DATABASE_NAME}
      - REDIS_HOSTNAME=redis
    ports:
      - 2283:2283
    security_opt:
      - no-new-privileges:true
    depends_on:
      - redis
      - database
    # extends:
      # file: hwaccel.transcoding.yml
      # service: vaapi # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - ${STORAGE}/Photos:/usr/src/app/upload
    healthcheck:
      disable: false

#   immich-machine-learning:
#     container_name: immich_machine_learning
#     # For hardware acceleration, add one of -[armnn, cuda, rocm, openvino, rknn] to the image tag.
#     # Example tag: ${IMMICH_VERSION:-release}-cuda
#     image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
#     # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
#     #   file: hwaccel.ml.yml
#     #   service: cpu # set to one of [armnn, cuda, rocm, openvino, openvino-wsl, rknn] for accelerated inference - use the `-wsl` version for WSL2 where applicable
#     # VAAPI (AMD / NVIDIA / Intel)
#     devices:
#       - /dev/dri:/dev/dri
#     volumes:
#       - model-cache:/cache
#     env_file:
#       - .env
#     restart: always
#     healthcheck:
#       disable: false
  
  redis:
    image: valkey/valkey:8.0.3-bookworm
    container_name: redis
    restart: always
    security_opt:
      - no-new-privileges:true
    healthcheck:
      test: redis-cli ping || exit 1

  database:
    image: tensorchord/pgvecto-rs:pg14-v0.3.0
    container_name: postgres
    restart: always
    security_opt:
      - no-new-privileges:true
    command: >-
      postgres -c shared_preload_libraries=vectors.so -c 'search_path="$$user", public, vectors' -c logging_collector=on -c max_wal_size=2GB -c shared_buffers=512MB -c wal_compression=on
    environment:
      - POSTGRES_DB=${DB_DATABASE_NAME}
      - POSTGRES_USER=${DB_USERNAME}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS='--data-checksums'
    volumes:
      - ./config/postgres:/var/lib/postgresql/data
    healthcheck:
      test: >-
        pg_isready --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" || exit 1; Chksum="$$(psql --dbname="$${POSTGRES_DB}" --username="$${POSTGRES_USER}" --tuples-only --no-align --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')"; echo "checksum failure count is $$Chksum"; [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m

  pgvector:
    image: pgvector/pgvector:0.7.4-pg17
    container_name: pgvector
    restart: always
    environment:
     - POSTGRES_DB=${POSTGRES_DB-openwebui}
     - POSTGRES_USER=${POSTGRES_USER-openwebui}
     - POSTGRES_PASSWORD=${POSTGRES_PASSWORD-openwebui}
    ports:
      - "5432:5432"
    configs:
      - source: pgvector_init
        target: /docker-entrypoint-initdb.d/init_pgvector.sql
    volumes:
      - ./config/pgvector:/var/lib/postgresql/data
    networks:
      - local-gpt

  # Local ChatGPT
  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.5.20
    container_name: open-webui
    restart: always
    depends_on:
      - pgvector
      # - ollama
    ports:
      - "8080:8080"
    environment:
      - GLOBAL_LOG_LEVEL=${GLOBAL_LOG_LEVEL-INFO}
      - DEFAULT_MODELS=${DEFAULT_MODELS}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE}
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - ENABLE_OPENAI_API=${ENABLE_OPENAI_API}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - VECTOR_DB=${VECTOR_DB}
      - PGVECTOR_DB_URL=postgresql://${POSTGRES_USER-openwebui}:${POSTGRES_PASSWORD-openwebui}@pgvector/${POSTGRES_DB-openwebui}
      - ENABLE_LOGIN_FORM=${ENABLE_LOGIN_FORM}
      - ENABLE_OAUTH_SIGNUP=${ENABLE_OAUTH_SIGNUP}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
      - GITHUB_CLIENT_REDIRECT_URI=${GITHUB_CLIENT_REDIRECT_URI}
    volumes:
      - ./config/open-webui-models:/models
      - ./config/open-webui:/app/backend/data
    networks:
      - local-gpt